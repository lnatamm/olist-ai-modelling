{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análise de Regressão - Olist Freight Value\n",
        "\n",
        "## Objetivo\n",
        "Prever o valor do frete (freight_value) usando diferentes modelos de regressão.\n",
        "\n",
        "## Requisitos Obrigatórios\n",
        "- ✅ Regressão Linear\n",
        "- ✅ PCA para redução de dimensionalidade  \n",
        "- ✅ 3 Métricas: R², MAE, RMSE\n",
        "\n",
        "## Modelos Comparados\n",
        "1. **Linear Regression** (obrigatório)\n",
        "2. **Random Forest Regressor**\n",
        "3. **Decision Tree Regressor**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeRegressor\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "# Importar bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Carregamento dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar datasets\n",
        "order_items = pd.read_csv('data/olist_order_items_dataset.csv')\n",
        "products = pd.read_csv('data/olist_products_dataset.csv')\n",
        "orders = pd.read_csv('data/olist_orders_dataset.csv')\n",
        "customers = pd.read_csv('data/olist_customers_dataset.csv')\n",
        "sellers = pd.read_csv('data/olist_sellers_dataset.csv')\n",
        "\n",
        "print(\"Dados carregados:\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar feature de volume do produto\n",
        "products['volume'] = (products['product_length_cm'] * \n",
        "                      products['product_height_cm'] * \n",
        "                      products['product_width_cm'])\n",
        "\n",
        "# Preencher valores ausentes na categoria\n",
        "products['product_category_name'] = products['product_category_name'].fillna('Indefinido')\n",
        "\n",
        "print(\"Features criadas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Merge e Preparação dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge dos dados\n",
        "data = (order_items\n",
        "        .merge(products, on='product_id')\n",
        "        .merge(orders, on='order_id')\n",
        "        .merge(customers, on='customer_id')\n",
        "        .merge(sellers, on='seller_id'))\n",
        "\n",
        "print(\"Dados unidos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Criação de Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar feature binária: mesmo estado?\n",
        "data['same_state'] = (data['customer_state'] == data['seller_state']).astype(int)\n",
        "\n",
        "# Codificar variáveis categóricas\n",
        "data['customer_state'] = data['customer_state'].astype('category').cat.codes\n",
        "data['seller_state'] = data['seller_state'].astype('category').cat.codes\n",
        "data['product_category'] = data['product_category_name'].astype('category').cat.codes\n",
        "\n",
        "# Definir features para o modelo\n",
        "features = [\n",
        "    'volume', \n",
        "    'product_weight_g', \n",
        "    'customer_state', \n",
        "    'seller_state', \n",
        "    'same_state', \n",
        "    'product_category'\n",
        "]\n",
        "\n",
        "# Preparar X e y (removendo NaN)\n",
        "X = data[features].dropna()\n",
        "y = data.loc[X.index, 'freight_value']\n",
        "\n",
        "print(f\"Features criadas: {features}\")\n",
        "print(f\"Target (Frete) - média: R$ {y.mean():.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train/Test Split e Normalização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dividir em treino e teste (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizar os dados (necessário para PCA)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Divisão dos dados (20/80)\")\n",
        "print(\"Normalização aplicada com StandardScaler\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. PCA - Redução de Dimensionalidade (Obrigatório)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aplicar PCA mantendo 95% da variância\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "print(\"PCA aplicado:\")\n",
        "print(f\"Dimensões originais: {X_train_scaled.shape[1]}\")\n",
        "print(f\"Dimensões após PCA: {X_train_pca.shape[1]}\")\n",
        "print(f\"\\nComponentes principais mantidos: {len(pca.explained_variance_ratio_)}\")\n",
        "print(f\"Features originais: {features}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Definição dos Modelos de Regressão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir os 3 modelos para comparação\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Random Forest': RandomForestRegressor(\n",
        "        n_estimators=100, \n",
        "        max_depth=15, \n",
        "        min_samples_leaf=2, \n",
        "        max_features='sqrt', \n",
        "        random_state=42, \n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    'Decision Tree': DecisionTreeRegressor(\n",
        "        max_depth=15, \n",
        "        min_samples_leaf=2, \n",
        "        ccp_alpha=0.0, \n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "print(\"Modelos definidos:\")\n",
        "for i, model_name in enumerate(models.keys(), 1):\n",
        "    print(f\"   {i}. {model_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Treinamento e Avaliação dos Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dicionário para armazenar resultados\n",
        "results = {}\n",
        "\n",
        "# Treinar e avaliar cada modelo\n",
        "for model_name, model in models.items():\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Modelo: {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Treinar modelo\n",
        "    model.fit(X_train_pca, y_train)\n",
        "    \n",
        "    # Predições\n",
        "    y_pred = model.predict(X_test_pca)\n",
        "    \n",
        "    # Calcular as 3 métricas obrigatórias\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "    \n",
        "    # Calcular acurácia com tolerância\n",
        "    tolerance = 0.2  # 20% de tolerância\n",
        "    accuracy = (abs(y_test - y_pred) / y_test <= tolerance).mean() * 100\n",
        "    \n",
        "    # Armazenar resultados\n",
        "    results[model_name] = {\n",
        "        'R²': r2,\n",
        "        'MAE': mae,\n",
        "        'RMSE': rmse,\n",
        "        'Acurácia (±20%)': accuracy\n",
        "    }\n",
        "    \n",
        "    # Exibir métricas\n",
        "    print(f\"R² Score: {r2:.4f}\")\n",
        "    print(f\"MAE (Mean Absolute Error): R$ {mae:.2f}\")\n",
        "    print(f\"RMSE (Root Mean Squared Error): R$ {rmse:.2f}\")\n",
        "    print(f\"Predições dentro de ±20%: {accuracy:.2f}%\")\n",
        "    print()\n",
        "\n",
        "print(\"Todos os modelos foram treinados e avaliados!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Comparação dos Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tabela comparativa dos modelos\n",
        "print(f\"{'='*70}\")\n",
        "print(\"COMPARAÇÃO DOS MODELOS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"{'Modelo':<25} {'R²':<10} {'MAE':<12} {'RMSE':<12} {'Acurácia':<10}\")\n",
        "print(f\"{'-'*70}\")\n",
        "\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"{model_name:<25} {metrics['R²']:<10.4f} R$ {metrics['MAE']:<9.2f} R$ {metrics['RMSE']:<9.2f} {metrics['Acurácia (±20%)']:<9.2f}%\")\n",
        "\n",
        "# Identificar o melhor modelo baseado em R²\n",
        "best_model = max(results.items(), key=lambda x: x[1]['R²'])\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Melhor modelo (por R²): {best_model[0]}\")\n",
        "print(f\"   - R² Score: {best_model[1]['R²']:.4f}\")\n",
        "print(f\"   - MAE: R$ {best_model[1]['MAE']:.2f}\")\n",
        "print(f\"   - RMSE: R$ {best_model[1]['RMSE']:.2f}\")\n",
        "print(f\"   - Acurácia (±20%): {best_model[1]['Acurácia (±20%)']:.2f}%\")\n",
        "print(f\"{'='*70}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
